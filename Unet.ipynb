{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rasterio                  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "import fiona                     # I/O vector data (shape, geojson, ...)\n",
    "import pyproj                    # Change coordinate reference system\n",
    "import geopandas\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import numpy as np               # numerical array manipulation\n",
    "import os\n",
    "from PIL import Image\n",
    "from detection.dataset.tree_dataset import TreeDataset\n",
    "from detection.dataset.static_dataset import StaticGenerator\n",
    "from detection.detectors.unet import UNet\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 5\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 400\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 2000\n",
    "AUGMENT_BRIGHTNESS = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = UNet([BATCH_SIZE, 256, 256, 3], 1e-3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"weights/UNet/{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=30) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sd = StaticGenerator('/Users/kari/Vision/Dataset/Hamburg/patches/','patch','mask', 0.2, 0.1)\n",
    "aug_gen = sd.static_generator(1, 'training')\n",
    "valid = sd.static_generator(1, 'validation')\n",
    "# vs = [next(valid) for _ in range(5)]\n",
    "# valid_x, valid_y = map(list, zip(*vs))\n",
    "valid_x, valid_y = next(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step_count = MAX_TRAIN_STEPS\n",
    "loss_history = [model.fit_generator(aug_gen, \n",
    "                             steps_per_epoch=step_count, \n",
    "                             epochs=NB_EPOCHS, \n",
    "                             validation_data=(valid_x, valid_y),\n",
    "                             callbacks=callbacks_list,\n",
    "                            workers=1 # the generator is not very thread safe\n",
    "                                       )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
